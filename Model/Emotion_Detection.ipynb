{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bruce0809\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import cv2\n",
    "import os\n",
    "import copy\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "def Emotion_Detection():\n",
    "    \n",
    "    model = load_model('CNN_model(small).h5')\n",
    "    cascade_file = 'haarcascade_frontface.xml'\n",
    "    cascade = cv2.CascadeClassifier(cascade_file)\n",
    "\n",
    "    capture = cv2.VideoCapture(0)    # n은 장치번호\n",
    "    capture.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n",
    "    capture.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n",
    "    frame_count = 0\n",
    "\n",
    "    while True:\n",
    "        ret, frame = capture.read()  # ret==카메라상태 저장, 정상작동은 True 반환\n",
    "                                     # frame== 현재프레임 저장\n",
    "        frame2 = copy.copy(frame)\n",
    "        frame_count += 1\n",
    "\n",
    "        # 이전 프레임과 비교를 위해 흑백으로 변환하기 --- (*2)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        face_list = cascade.detectMultiScale(gray)\n",
    "\n",
    "        if len(face_list) == 0:\n",
    "            quit()\n",
    "\n",
    "        for (x,y,w,h) in face_list:\n",
    "            roi = frame[y:y+h, x:x+w]\n",
    "            imagex = cv2.resize(roi, (200, 200))\n",
    "            #print(imagex.shape)\n",
    "            image_data = imagex.reshape(1, 200, 200,3 )\n",
    "\n",
    "            color = (255, 0, 0)\n",
    "\n",
    "            pred_y = model.predict(image_data) # --- (*4)\n",
    "            print(pred_y)\n",
    "\n",
    "            if np.argmax(pred_y) == 0:\n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness=4)\n",
    "                    cv2.putText(frame,'Positive',(x,y-20),cv2.FONT_ITALIC, 0.5, (255,255,255))  \n",
    "\n",
    "            elif np.argmax(pred_y) == 1:  \n",
    "                    cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness=4)\n",
    "                    cv2.putText(frame,'Neutral',(x,y-20),cv2.FONT_ITALIC, 0.5, (255,255,255))  \n",
    "            else:\n",
    "                np.argmax(pred_y) == 2\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, thickness=4)\n",
    "                cv2.putText(frame,'Negative',(x,y-20),cv2.FONT_ITALIC, 0.5, (255,255,255))          \n",
    "\n",
    "        cv2.imshow(\"VideoFrame\", frame) # 윈도우 창에 이미지 띄움\n",
    "        if cv2.waitKey(1) > 0:       # (time) 은 time 마다 키 입력상태 받아옴\n",
    "            break   \n",
    "\n",
    "    capture.release()                # 받아온 메모리 해제\n",
    "    cv2.destroyAllWindows()          # 모든 윈도우 창 닫기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
